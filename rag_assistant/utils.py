import logging
logging.getLogger("pdfminer").setLevel(logging.ERROR)
import os
import time
import shutil
from tqdm import tqdm
from retrying import retry
import pdfplumber
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from pdfminer.pdfparser import PDFSyntaxError
from rag_assistant import config


def parse_pdfs(pdf_dir: str) -> list[Document]:
    docs: list[Document] = []
    for fname in os.listdir(pdf_dir):
        if not fname.lower().endswith('.pdf'):
            continue
        path = os.path.join(pdf_dir, fname)
        try:
            print(f"[LOAD] –ó–∞–≥—Ä—É–∂–∞–µ–º PDF: {fname}")
            with pdfplumber.open(path) as pdf:
                for i, page in enumerate(pdf.pages):
                    text = page.extract_text()
                    if not text:
                        print(f"[WARN] –ü—É—Å—Ç–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {i+1} –≤ {fname}")
                        continue
                    meta = {'source': fname, 'page': i + 1}
                    docs.append(Document(page_content=text, metadata=meta))
        except PDFSyntaxError:
            print(f"[ERROR] –ü–æ–≤—Ä–µ–∂–¥—ë–Ω PDF: {fname}")
        except Exception as e:
            print(f"[ERROR] –û—à–∏–±–∫–∞ —Å {fname}: {e}")
    print(f"[RESULT] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(docs)} —Å—Ç—Ä–∞–Ω–∏—Ü –∏–∑ {len(os.listdir(pdf_dir))} PDF-—Ñ–∞–π–ª–æ–≤")
    return docs


@retry(stop_max_attempt_number=3, wait_fixed=1000)
from tqdm import tqdm
import time
import shutil
import os
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from rag_assistant.utils import parse_pdfs
from langchain.text_splitter import RecursiveCharacterTextSplitter

def get_or_create_vectorstore(pdf_dir, persist_dir, force_rebuild=False):
    embeddings = OpenAIEmbeddings(
        model="text-embedding-ada-002",
        batch_size=64,           # üîß –±–æ–ª—å—à–æ–π –±–∞—Ç—á ‚Äî –º–µ–Ω—å—à–µ –∑–∞–ø—Ä–æ—Å–æ–≤
        request_timeout=60,
        show_progress_bar=True
    )

    if not force_rebuild:
        try:
            vectordb = Chroma(
                persist_directory=persist_dir,
                embedding_function=embeddings
            )
            if vectordb._collection.count() > 0:
                print("[INFO] –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –±–∞–∑–∞ –≤–µ–∫—Ç–æ—Ä–æ–≤.")
                return vectordb
        except Exception as e:
            print(f"[WARN] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã: {e}")

    # –£–¥–∞–ª–∏–º —Å—Ç–∞—Ä—É—é –±–∞–∑—É, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if force_rebuild and os.path.exists(persist_dir):
        shutil.rmtree(persist_dir, ignore_errors=True)
    os.makedirs(persist_dir, exist_ok=True)

    # –®–∞–≥ 1: –∑–∞–≥—Ä—É–∑–∫–∞ –∏ —Ä–∞–∑–±–∏–≤–∫–∞ PDF
    docs = parse_pdfs(pdf_dir)
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    chunks = splitter.split_documents(docs)
    print(f"[INFO] –†–∞–∑–±–∏—Ç–æ –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤")

    # –®–∞–≥ 2: —Å–æ–∑–¥–∞—ë–º –ø—É—Å—Ç—É—é –±–∞–∑—É
    vectordb = Chroma(
        persist_directory=persist_dir,
        embedding_function=embeddings
    )

    # –®–∞–≥ 3: –∑–∞–≥—Ä—É–∂–∞–µ–º –±–∞—Ç—á–∞–º–∏
    batch_size = 64
    for i in tqdm(range(0, len(chunks), batch_size), desc="‚¨ÜÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –≤ Chroma"):
        chunk_batch = chunks[i:i + batch_size]
        try:
            vectordb.add_documents(chunk_batch)
            vectordb.persist()
            time.sleep(0.5)  # –∑–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏ API
        except Exception as e:
            print(f"[ERROR] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –±–∞—Ç—á–∞ {i // batch_size + 1}: {e}")

    print("[SUCCESS] –í—Å–µ —á–∞–Ω–∫–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É.")
    return vectordb
